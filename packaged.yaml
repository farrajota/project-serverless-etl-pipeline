AWSTemplateFormatVersion: '2010-09-09'
Description: 'A serverless ETL pipeline for storing and processing visitor gender
  hits couple with a gender service to predict a visitor''s gender by ID.

  '
Outputs:
  DynamodbTable:
    Description: Dynamodb Table ARN
    Value:
      Fn::GetAtt:
      - DynamoDBTable
      - Arn
  FirehoseStreamProcessFunction:
    Description: The Lambda Function that will process Firehose records
    Value:
      Ref: FirehoseStreamProcessFunction
  KinesisFirehoseDeliverStream:
    Description: Kinesis Firehose Delivery Stream ARN
    Value:
      Fn::GetAtt:
      - KinesisFirehoseDeliveryStream
      - Arn
  ProcessStreamDataFunction:
    Description: Lambda function that will process and compress the stream data stored
      in S3
    Value:
      Ref: ProcessStreamDataUpdateDynamodbFunction
  Region:
    Description: The region this template was launched in.
    Value:
      Ref: AWS::Region
  S3BucketCompressed:
    Description: S3 bucket to store the compressed stream data
    Value:
      Fn::GetAtt:
      - S3BucketCompressed
      - Arn
  S3BucketNameKinesisFirehose:
    Description: S3 bucket to store the streaming data from Kinesis Firehose
    Value:
      Fn::GetAtt:
      - S3BucketStoreFirehoseStream
      - Arn
Parameters:
  DynamodbKeyElementName:
    Default: clientid
    Description: Primary Key Name
    Type: String
  DynamodbKeyElementType:
    AllowedPattern: '[S|N]'
    ConstraintDescription: must be either S or N
    Default: S
    Description: Primary Key Type
    MaxLength: '1'
    MinLength: '1'
    Type: String
  DynamodbReadCapacityUnits:
    ConstraintDescription: must be between 5 and 10000
    Default: '5'
    Description: Provisioned read throughput
    MaxValue: '10000'
    MinValue: '5'
    Type: Number
  DynamodbTableName:
    Default: case-study-project-dynamodb-gender
    Description: Dynamodb's table name
    Type: String
  DynamodbWriteCapacityUnits:
    ConstraintDescription: must be between 5 and 10000
    Default: '5'
    Description: Provisioned write throughput
    MaxValue: '10000'
    MinValue: '5'
    Type: Number
  FirehoseBufferingInterval:
    Default: 60
    Description: How long Firehose will wait before writing a new batch into S3
    MaxValue: 900
    MinValue: 60
    Type: Number
  FirehoseBufferingSize:
    Default: 10
    Description: Maximum batch size in MB
    MaxValue: 128
    MinValue: 1
    Type: Number
  FirehoseCompressionFormat:
    AllowedValues:
    - UNCOMPRESSED
    - GZIP
    - Snappy
    Default: UNCOMPRESSED
    Description: Compression format used by Kinesis Firehose
    Type: String
  FirehoseLambdaMemorySize:
    AllowedValues:
    - 128
    - 192
    - 256
    - 320
    - 384
    - 448
    - 512
    - 576
    - 640
    - 704
    - 768
    - 832
    - 896
    - 960
    - 1024
    - 1088
    - 1152
    - 1216
    - 1280
    - 1344
    - 1408
    - 1472
    - 1536
    Default: 128
    Type: String
  FirehoseLambdaTimeout:
    Default: 60
    Description: Maximum Lambda execution time in seconds
    MaxValue: 900
    MinValue: 5
    Type: Number
  FirehoseS3Prefix:
    Default: firehose/
    Description: The S3 Key prefix for Kinesis Firehose.
    Type: String
  ProcessLambdaMemorySize:
    AllowedValues:
    - 128
    - 192
    - 256
    - 320
    - 384
    - 448
    - 512
    - 576
    - 640
    - 704
    - 768
    - 832
    - 896
    - 960
    - 1024
    - 1088
    - 1152
    - 1216
    - 1280
    - 1344
    - 1408
    - 1472
    - 1536
    Default: '256'
    Type: Number
  ProcessLambdaTimeout:
    Default: '300'
    Description: Maximum Lambda execution time in seconds
    MaxValue: '900'
    MinValue: '5'
    Type: Number
  S3BucketCompressedName:
    Default: case-study-stream-compressed
    Description: S3 bucket to store the compressed stream data
    Type: String
  S3BucketFirehoseStreamName:
    Default: case-study-kinesis-firehose-stream
    Description: S3 bucket to store the firehose stream data
    Type: String
Resources:
  DynamoDBTable:
    Properties:
      AttributeDefinitions:
      - AttributeName:
          Ref: DynamodbKeyElementName
        AttributeType:
          Ref: DynamodbKeyElementType
      KeySchema:
      - AttributeName:
          Ref: DynamodbKeyElementName
        KeyType: HASH
      ProvisionedThroughput:
        ReadCapacityUnits:
          Ref: DynamodbReadCapacityUnits
        WriteCapacityUnits:
          Ref: DynamodbWriteCapacityUnits
      TableName:
        Ref: DynamodbTableName
    Type: AWS::DynamoDB::Table
  FirehoseDeliveryPolicy:
    Properties:
      PolicyDocument:
        Statement:
        - Action:
          - lambda:InvokeFunction
          - s3:AbortMultipartUpload
          - s3:GetBucketLocation
          - s3:GetObject
          - s3:ListBucket
          - s3:ListBucketMultipartUploads
          - s3:PutObject
          Effect: Allow
          Resource:
          - Fn::GetAtt:
            - FirehoseStreamProcessFunction
            - Arn
          - Fn::Join:
            - ''
            - - 'arn:aws:s3:::'
              - Ref: S3BucketStoreFirehoseStream
          - Fn::Join:
            - ''
            - - 'arn:aws:s3:::'
              - Ref: S3BucketStoreFirehoseStream
              - '*'
        Version: '2012-10-17'
      PolicyName: firehose_delivery_policy
      Roles:
      - Ref: FirehoseDeliveryRole
    Type: AWS::IAM::Policy
  FirehoseDeliveryRole:
    Properties:
      AssumeRolePolicyDocument:
        Statement:
        - Action: sts:AssumeRole
          Condition:
            StringEquals:
              sts:ExternalId:
                Ref: AWS::AccountId
          Effect: Allow
          Principal:
            Service: firehose.amazonaws.com
          Sid: ''
        Version: '2012-10-17'
    Type: AWS::IAM::Role
  FirehoseStreamProcessFunction:
    Properties:
      CodeUri: s3://data-pipeline-etl-project-lambda-code/74ff9f29c0ef496de46685b154335435
      Description: An Amazon Kinesis Firehose stream processor that appends a timestamp
        to input records.
      Handler: app.lambda_handler
      MemorySize:
        Ref: FirehoseLambdaMemorySize
      Runtime: python3.7
      Timeout:
        Ref: FirehoseLambdaTimeout
    Type: AWS::Serverless::Function
  KinesisFirehoseDeliveryStream:
    DependsOn:
    - FirehoseDeliveryPolicy
    Properties:
      DeliveryStreamType: DirectPut
      ExtendedS3DestinationConfiguration:
        BucketARN:
          Fn::GetAtt:
          - S3BucketStoreFirehoseStream
          - Arn
        BufferingHints:
          IntervalInSeconds:
            Ref: FirehoseBufferingInterval
          SizeInMBs:
            Ref: FirehoseBufferingSize
        CompressionFormat:
          Ref: FirehoseCompressionFormat
        Prefix:
          Ref: FirehoseS3Prefix
        ProcessingConfiguration:
          Enabled: 'true'
          Processors:
          - Parameters:
            - ParameterName: LambdaArn
              ParameterValue:
                Fn::GetAtt:
                - FirehoseStreamProcessFunction
                - Arn
            Type: Lambda
        RoleARN:
          Fn::GetAtt:
          - FirehoseDeliveryRole
          - Arn
    Type: AWS::KinesisFirehose::DeliveryStream
  ProcessStreamDataUpdateDynamodbFunction:
    Properties:
      CodeUri: s3://data-pipeline-etl-project-lambda-code/570e5569c3390a3399bb8bbc6b8e2545
      Description: Compresses the stream data into parquet format, processes the hits
        per client and updates the state of the dynamodb table. It is triggered by
        a object creation event in the S3 bucket where stream data is stored as an
        object/file.
      Environment:
        Variables:
          DYNAMODB_TABLE:
            Ref: DynamodbTableName
          S3_BUCKET_DEST:
            Ref: S3BucketCompressed
          S3_BUCKET_SOURCE:
            Ref: S3BucketFirehoseStreamName
      Events:
        S3FileListener:
          Properties:
            Bucket:
              Ref: S3BucketStoreFirehoseStream
            Events: s3:ObjectCreated:*
          Type: S3
      Handler: app.lambda_handler
      MemorySize:
        Ref: ProcessLambdaMemorySize
      Policies:
      - Statement:
        - Action:
          - s3:PutObject
          Effect: Allow
          Resource:
          - Fn::Join:
            - ''
            - - 'arn:aws:s3:::'
              - Ref: S3BucketCompressed
              - '*'
        - Action:
          - s3:Get*
          - s3:List*
          - s3:DeleteObject
          Effect: Allow
          Resource:
          - arn:aws:s3:::*
        - Action:
          - cloudwatch:PutMetricData
          Effect: Allow
          Resource: '*'
        - Action:
          - dynamodb:*
          Effect: Allow
          Resource:
            Fn::GetAtt:
            - DynamoDBTable
            - Arn
        Version: '2012-10-17'
      Runtime: python3.7
      Timeout:
        Ref: ProcessLambdaTimeout
    Type: AWS::Serverless::Function
  S3BucketCompressed:
    Properties:
      AccessControl: Private
      BucketName:
        Ref: S3BucketCompressedName
    Type: AWS::S3::Bucket
  S3BucketStoreFirehoseStream:
    Properties:
      AccessControl: Private
      BucketName:
        Ref: S3BucketFirehoseStreamName
    Type: AWS::S3::Bucket
Transform: AWS::Serverless-2016-10-31
